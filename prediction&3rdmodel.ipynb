{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction part of 1st and 3rd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 14:15:50.594965: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-14 14:15:54.266895: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 14:16:03.056412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-14 14:16:26.663426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13508 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5\n",
      "2023-06-14 14:16:30.862807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 14:16:30.865567: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 14:16:30.867538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 14:16:31.135494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 14:16:31.137083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 14:16:31.138251: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 14:16:31.382696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 14:16:31.384812: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 14:16:31.386423: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 14:16:33.953392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 14:16:33.955147: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 14:16:33.956409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 14:16:34.303460: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 14:16:34.305611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 14:16:34.307363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 14:16:34.605425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 14:16:34.607267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 14:16:34.608789: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 14:17:03.824282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 43s 43s/step\n",
      "['use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing', 'use', 'use', 'discourse', 'i', 'a', 'a', 'doing', 'doing', 'use', 'i', 'a', 'a', 'discourse', 'discourse', 'doing', 'doing', 'doing', 'a', 'a', 'doing', 'doing', 'doing', 'use', 'use', 'doing', 'i', 'i', 'i', 'i', 'use', 'doing', 'i', 'use', 'i', 'i', 'use', 'doing', 'i', 'doing', 'use', 'use', 'doing', 'doing', 'doing', 'doing', 'doing', 'doing', 'discourse', 'use', 'doing', 'discourse', 'use', 'doing', 'constable', 'doing', 'doing', 'use', 'a', 'doing', 'doing', 'a', 'doing', 'i', 'doing']\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "text_data = \"The feeling you can know so much Without knowing anything at all And now that I can put this down If I had known what I know now \\\n",
    "I never would've played so nonchalant Taxi cabs and busy streets That never bring you back to me I can't help but wish you took me with you And this is when the \\\n",
    "    feeling sinks in I don't wanna miss you like this Come back, be here, come back, be here I guess you're in London today And I don't wanna need you this way \\\n",
    "        Come back, be here, come back, be here You might also like This is falling in love in the cruelest way \"\n",
    "# Initialize tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "with open(\"/home/narayana.mayya@sapt.local/projects/Antoine_coefficient_modelling/extra_stuff/char-rnn-keras-master/data/char_to_idx_dictcheck_indexreset.json\", 'r') as file:\n",
    "    char_to_idx = json.load(file)\n",
    " \n",
    "vocab_size = len(char_to_idx)\n",
    "tokenizer.word_index=char_to_idx\n",
    "T = tokenizer.texts_to_sequences(text_data)\n",
    "T = np.asarray([lst for lst in T if lst], dtype=np.int32)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"/home/narayana.mayya@sapt.local/projects/Antoine_coefficient_modelling/extra_stuff/Test/model/model_run4.h5\")  # Load the entire model from the file\n",
    "\n",
    "transposed_input = np.transpose(T[:64], (1, 0))\n",
    "repeated_input = np.tile(transposed_input, (16, 1))\n",
    "\n",
    "res = model.predict(repeated_input)\n",
    "index_word = {index: word for word, index in char_to_idx.items()}\n",
    "# Apply argmax along the last dimension\n",
    "argmax_indices = np.argmax(res, axis=-1)\n",
    "# Convert the argmax indices to words using the index_word dictionary\n",
    "ind_check = [index for indices in argmax_indices for index in indices]\n",
    "words = [index_word[index] for indices in argmax_indices for index in indices]\n",
    "# Print the predicted words\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing use use discourse i a a doing doing use i a a discourse discourse doing doing doing a a doing doing doing use use doing i i i i use doing i use i i use doing i doing use use doing doing doing doing doing doing discourse use doing discourse use doing constable doing doing use a doing doing a doing i doing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(words) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 15:22:03.574273: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-14 15:22:03.649042: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 15:22:04.925526: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import pickle\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /home/narayana.mayya@sapt.local/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "2023-06-14 15:23:06.964008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13644 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2023-06-14 15:23:07.638403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 15:23:07.641667: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 15:23:07.643334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 15:23:07.900522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 15:23:07.901934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 15:23:07.902942: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 15:23:08.145921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 15:23:08.147988: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 15:23:08.149444: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 15:24:15.172016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 15:24:15.173578: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 15:24:15.174682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 15:24:15.446128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 15:24:15.448388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 15:24:15.450061: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 15:24:15.698200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 15:24:15.700292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 15:24:15.701749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 15:24:36.750655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 15:24:36.752626: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 15:24:36.753985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 15:24:36.945770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 15:24:36.947337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 15:24:36.948545: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 15:24:37.472765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-14 15:24:37.474707: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-14 15:24:37.476163: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-14 15:24:47.827853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-14 15:24:49.234507: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f2dd81ba8e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-14 15:24:49.234561: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-06-14 15:24:49.713749: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-14 15:24:52.579353: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 32s 34ms/step - loss: 1.1092 - accuracy: 0.6182\n",
      "Epoch 2/2\n",
      "438/438 [==============================] - 13s 29ms/step - loss: 1.1027 - accuracy: 0.6200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f30381bef70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64\n",
    "DATA_DIR = '/home/narayana.mayya@sapt.local/projects/Antoine_coefficient_modelling/extra_stuff/Test/data'\n",
    "\n",
    "# Load text data from file\n",
    "text_data_file_path = '/home/narayana.mayya@sapt.local/projects/Antoine_coefficient_modelling/extra_stuff/Test/data/input.txt'\n",
    "with open(text_data_file_path, 'r') as file:\n",
    "    text_data = file.read().splitlines()\n",
    "# Initialize tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# Fit tokenizer on text data\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "'''\n",
    "tokenizer_file_path = '/home/narayana.mayya@sapt.local/projects/Antoine_coefficient_modelling/extra_stuff/Test/model/tokenizer_if_needed.pkl'\n",
    "with open(tokenizer_file_path, 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)\n",
    "'''\n",
    "# Create a dictionary of unique words\n",
    "word_index = tokenizer.word_index\n",
    "# Print the dictionary\n",
    "#print(\"All unique words from raw data: \", len(word_index))  #8130\n",
    "# Download the English word corpus from NLTK\n",
    "nltk.download('words')\n",
    "# Get the set of English words\n",
    "english_words = set(nltk.corpus.words.words())\n",
    "# Filter out words in word_index that are not valid English words\n",
    "valid_word_index = {word:index for word,index in word_index.items() if word in english_words}\n",
    "char_to_idx = {key: index + 1 for index, key in enumerate(valid_word_index)}   \n",
    "#char_to_idx = valid_word_index \n",
    "\n",
    "#print(\"Number of unique characters: \" + str(len(char_to_idx))) #4474\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'char_to_idx_new_code.json'), 'w') as f:\n",
    "    json.dump(char_to_idx, f)\n",
    "\n",
    "#idx_to_char = { i: ch for (ch, i) in char_to_idx.items() }\n",
    "vocab_size = len(char_to_idx) #4474\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 512, batch_input_shape=(BATCH_SIZE, SEQ_LENGTH)))\n",
    "for i in range(3):\n",
    "    model.add(LSTM(256, return_sequences=True, stateful=True))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(TimeDistributed(Dense(vocab_size))) \n",
    "model.add(Activation('softmax'))\n",
    "#model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "'''\n",
    "#Train data generation\n",
    "text = ' '.join(text_data)\n",
    "T = tokenizer.texts_to_sequences(text)\n",
    "#print(\"Length of text:\" + str(T.size)) \n",
    "T = np.asarray([lst for lst in T if lst], dtype=np.int32)\n",
    "print(T.shape) #(506795, 1)\n",
    "mask = np.all(np.isin(T, list(char_to_idx.values())), axis=1)\n",
    "T = T[mask]\n",
    "print(T.shape) #(448858, 1)\n",
    "\n",
    "length = T.shape[0]; \n",
    "X_final = np.array([[]])\n",
    "Y_final = np.array([[[]]])\n",
    "batch_chars = int(length / BATCH_SIZE); #28053\n",
    "for start in tqdm(range(0, batch_chars - SEQ_LENGTH, SEQ_LENGTH)): \n",
    "    X = np.zeros((BATCH_SIZE, SEQ_LENGTH)) \n",
    "    Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, vocab_size)) \n",
    "    for batch_idx in range(0, BATCH_SIZE): # (0,16)\n",
    "        for i in range(0, SEQ_LENGTH): #(0,64)\n",
    "            X[batch_idx, i] = T[batch_chars * batch_idx + start + i] # \n",
    "            Y[batch_idx, i, T[batch_chars * batch_idx + start + i + 1]] = 1    \n",
    "    if X_final.size == 0:\n",
    "        X_final = X\n",
    "    else:\n",
    "        X_final = np.concatenate((X_final, X))\n",
    "    \n",
    "    if Y_final.size == 0:\n",
    "        Y_final = Y\n",
    "    else:\n",
    "        Y_final = np.concatenate((Y_final,Y))   \n",
    "'''\n",
    "# Define callbacks\n",
    "checkpoint_filepath = \"/home/narayana.mayya@sapt.local/projects/Antoine_coefficient_modelling/extra_stuff/data/models/new_code_next500_test-{loss:.4f}_epoch-{epoch:02d}_{accuracy:.4f}.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_filepath, save_best_only=True, monitor='loss')\n",
    "\n",
    "#early_stopping_callback = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "#model.load_weights(\"/home/narayana.mayya@sapt.local/projects/Antoine_coefficient_modelling/extra_stuff/Test/actual_data/models/model_chpt_Bidir32_loss_emb512_test_Drop0.5-2.3074_epoch-02_6.6678.h5\") \n",
    "X_final = np.load('X_final.npy')\n",
    "Y_final = np.load('Y_final.npy')\n",
    "# Train the model\n",
    "model = load_model(\"/home/narayana.mayya@sapt.local/projects/Antoine_coefficient_modelling/extra_stuff/data/models/new_code_next500-1.0709_epoch-496_0.6326.h5\")\n",
    "model.fit(X_final, Y_final, epochs=2, batch_size=BATCH_SIZE, callbacks=[checkpoint_callback])   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('X_final.npy', X_final)\n",
    "#np.save('Y_final.npy', Y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7008, 64)\n",
      "(7008, 64, 4474)\n"
     ]
    }
   ],
   "source": [
    "#X_final = np.load('X_final.npy')\n",
    "#Y_final = np.load('Y_final.npy')\n",
    "print(X_final.shape)\n",
    "print(Y_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (16, 64, 512)             2290688   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (16, 64, 256)             787456    \n",
      "                                                                 \n",
      " dropout (Dropout)           (16, 64, 256)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (16, 64, 256)             525312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (16, 64, 256)             0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (16, 64, 256)             525312    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (16, 64, 256)             0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (16, 64, 4474)           1149818   \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " activation (Activation)     (16, 64, 4474)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,278,586\n",
      "Trainable params: 5,278,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = load_model(\"/home/narayana.mayya@sapt.local/projects/new_few_apps_streamlit/streamlit_datafile_links/lyrics/new_code_next500-1.0709_epoch-496_0.6326.h5\") \n",
    "model.summary() # for 1st and 3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 final loss and accuracy\n",
    "Epoch 1/2\n",
    "loss = 0.7341960072517395, acc = 0.73046875\n",
    "\n",
    "Epoch 2/2\n",
    "loss = 0.7732210755348206, acc = 0.720703125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
